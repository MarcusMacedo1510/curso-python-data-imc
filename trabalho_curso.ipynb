{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo principal deste trabalho é projetar e analisar os modelos de aprendizado de\n",
        "máquina criados para identificar corretamente a espécie de flor na base das características\n",
        "observadas da sépala e da pétala. Durante o tempo de execução do projeto, você terá que\n",
        "projetar o pré- processamento dos dados, experimentar com diferentes métodos de\n",
        "classificação e avaliar o desempenho do modelo gerado."
      ],
      "metadata": {
        "id": "qb99C6lZrkrG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UJ9Y1aSIh8IE"
      },
      "outputs": [],
      "source": [
        "# Importação de Bibliotecas necessárias ao Projeto\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classe do Projeto\n",
        "\n",
        "class Iris():\n",
        "    def __init__(self):\n",
        "      self.df = None\n",
        "      self.X_treinamento = None\n",
        "      self.X_teste = None\n",
        "      self.y_treinamento = None\n",
        "      self.y_teste = None\n",
        "      self.model = None\n",
        "      self.accuracy = None\n",
        "      self.precision = None\n",
        "      self.recall = None\n",
        "      self.f1_score = None\n",
        "      self.confusion_matrix = None\n",
        "      self.classification_report = None\n",
        "\n",
        "\n",
        "\n",
        "    def CarregarDataset(self, path):\n",
        "        \"\"\"\n",
        "        Carrega o conjunto de dados a partir de um arquivo CSV.\n",
        "\n",
        "        Parâmetros:\n",
        "        - path (str): Caminho para o arquivo CSV contendo o dataset.\n",
        "\n",
        "        O dataset é carregado com as seguintes colunas: SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm e Species.\n",
        "        \"\"\"\n",
        "        names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
        "        self.df = pd.read_csv(path, names=names)\n",
        "\n",
        "    def TratamentoDeDados(self):\n",
        "        \"\"\"\n",
        "        Realiza o pré-processamento dos dados carregados.\n",
        "\n",
        "        Sugestões para o tratamento dos dados:\n",
        "            * Utilize `self.df.head()` para visualizar as primeiras linhas e entender a estrutura.\n",
        "            * Verifique a presença de valores ausentes e faça o tratamento adequado.\n",
        "            * Considere remover colunas ou linhas que não são úteis para o treinamento do modelo.\n",
        "\n",
        "        Dicas adicionais:\n",
        "            * Explore gráficos e visualizações para obter insights sobre a distribuição dos dados.\n",
        "            * Certifique-se de que os dados estão limpos e prontos para serem usados no treinamento do modelo.\n",
        "        \"\"\"\n",
        "        # Exibindo as primeiras linhas:\n",
        "        print('Visualizando as primeiras linhas ...\\n')\n",
        "        print(self.df.head())\n",
        "\n",
        "        # Verificando a existência de valores Nulos:\n",
        "        print('\\nVerificando a presença de valores ausentes ...\\n')\n",
        "        print(self.df.isnull().sum())\n",
        "\n",
        "        #Verificando dados nulos:\n",
        "        print('\\nOlhando os dados nulos nas colunas...\\n')\n",
        "        for col in self.df.columns.tolist():\n",
        "          print('Número de missing na coluna {}: {}'.format(col, self.df[col].isnull().sum()))\n",
        "\n",
        "        #Verificando necessidade de remoção de colunas ou linhas:\n",
        "        print('\\nNão será necessário a remoção de colunas ou linhas...\\n')\n",
        "\n",
        "        #Verificando dados estatísticos do dataframe:\n",
        "        print('\\nObtendo uma descrição dos dados...\\n')\n",
        "        print(self.df.describe())\n",
        "\n",
        "        #Verificando contagem de valores pelo atributo: Species\n",
        "        print('\\nObtendo uma contagem de valores...\\n')\n",
        "        print(self.df['Species'].value_counts())\n",
        "\n",
        "        #Verificando correlação pelo heatmap\n",
        "        print('\\nOlhando correlação de colunas numéricas pelo heatmap...\\n')\n",
        "\n",
        "        hm = self.df.copy()\n",
        "        hm = hm.replace(\"Iris-setosa\", 0)\n",
        "        hm = hm.replace(\"Iris-versicolor\", 1)\n",
        "        hm = hm.replace(\"Iris-virginica\", 2)\n",
        "\n",
        "        hm = hm.corr()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        im = ax.imshow(hm, cmap='bwr')\n",
        "\n",
        "        ax.set_xticks(np.arange(len(hm.columns)), labels=hm.columns)\n",
        "        ax.set_yticks(np.arange(len(hm.columns)), labels=hm.columns)\n",
        "\n",
        "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "        hm = hm.rename(columns={\"Species\": 0, \"SepalLengthCm\": 1, \"SepalWidthCm\": 2, \"PetalLengthCm\": 3, \"PetalWidthCm\": 4})\n",
        "\n",
        "        for i in hm:\n",
        "            for j in hm:\n",
        "                text = ax.text(j, i, round(hm[i][j], 2), ha=\"center\", va=\"center\", color=\"black\")\n",
        "        plt.show()\n",
        "\n",
        "        #Verificando a distribuição de Sepal Length pelo BloxPlot\n",
        "        print('\\nOlhando a distribuição de Sepal Length pelo BloxPlot...\\n')\n",
        "\n",
        "        plt.figure(figsize=(15,8))\n",
        "        sns.boxplot(x='Species',y='SepalLengthCm',data=self.df.sort_values('SepalLengthCm',ascending=False))\n",
        "        plt.show()\n",
        "\n",
        "        #Verificando a relação entre Species e Sepal Width\n",
        "        print('\\nAnálise de dados entre Species e Sepal Length x Width...\\n')\n",
        "\n",
        "        fig = self.df[self.df.Species=='Iris-setosa'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='red', label='Setosa')\n",
        "        self.df[self.df.Species=='Iris-versicolor'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='cyan', label='versicolor',ax=fig)\n",
        "        self.df[self.df.Species=='Iris-virginica'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='black', label='virginica', ax=fig)\n",
        "        fig.set_xlabel(\"Sepal Length\")\n",
        "        fig.set_ylabel(\"Sepal Width\")\n",
        "        fig.set_title(\"Sepal Length x Width\")\n",
        "        fig=plt.gcf()\n",
        "        fig.set_size_inches(10,6)\n",
        "        plt.show()\n",
        "\n",
        "        #Verificando a relação entre Species e Sepal Width\n",
        "        print('\\nAnálise de dados: entre Species e Petal Length x Width...\\n')\n",
        "\n",
        "        fig = self.df[self.df.Species=='Iris-setosa'].plot(kind='scatter',x='PetalLengthCm',y='PetalWidthCm',color='orange', label='Setosa')\n",
        "        self.df[self.df.Species=='Iris-versicolor'].plot(kind='scatter',x='PetalLengthCm',y='PetalWidthCm',color='blue', label='versicolor',ax=fig)\n",
        "        self.df[self.df.Species=='Iris-virginica'].plot(kind='scatter',x='PetalLengthCm',y='PetalWidthCm',color='green', label='virginica', ax=fig)\n",
        "        fig.set_xlabel(\"Petal Length\")\n",
        "        fig.set_ylabel(\"Petal Width\")\n",
        "        fig.set_title(\"Petal Length x Width\")\n",
        "        fig=plt.gcf()\n",
        "        fig.set_size_inches(10,6)\n",
        "        plt.show()\n",
        "\n",
        "    def Treinamento_SVM(self):\n",
        "        \"\"\"\n",
        "        Treina o modelo de machine learning.\n",
        "\n",
        "        Detalhes:\n",
        "            * Utilize a função `train_test_split` para dividir os dados em treinamento e teste.\n",
        "            * Escolha o modelo de machine learning que queira usar. Lembrando que não precisa ser SMV e Regressão linear.\n",
        "            * Experimente técnicas de validação cruzada (cross-validation) para melhorar a acurácia final.\n",
        "\n",
        "        Nota: Esta função deve ser ajustada conforme o modelo escolhido.\n",
        "        \"\"\"\n",
        "        # Dividindo os dados principais em treinamento and teste: 70% (treinamento) e 30% (testes)\n",
        "\n",
        "        treinamento, teste = train_test_split(self.df, test_size = 0.3)\n",
        "        print(treinamento.shape)\n",
        "        print(teste.shape)\n",
        "\n",
        "        self.X_treinamento = treinamento[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\n",
        "        self.y_treinamento = treinamento.Species\n",
        "\n",
        "        self.X_teste = teste[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\n",
        "        self.y_teste = teste.Species\n",
        "\n",
        "        print(f'Verificando Datasets\\nTreinamento: \\n{self.X_treinamento.head(5)}\\n\\nTestes: \\n{self.X_teste.head(5)}\\n\\nSaida:\\n {self.y_treinamento.head()}')\n",
        "\n",
        "        # SVM\n",
        "        print('\\nTREINANDO COM O SVM - SUPORT VECTOR MACHINE\\n')\n",
        "\n",
        "        self.model = svm.SVC()\n",
        "        self.model.fit(self.X_treinamento, self.y_treinamento)  # Treina o modelo com os dados de treinamemto\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def Teste_SVM(self):\n",
        "        \"\"\"\n",
        "        Avalia o desempenho do modelo treinado nos dados de teste.\n",
        "\n",
        "        Esta função deve ser implementada para testar o modelo e calcular métricas de avaliação relevantes,\n",
        "        como acurácia, precisão, ou outras métricas apropriadas ao tipo de problema.\n",
        "        \"\"\"\n",
        "        prediction = self.model.predict(self.X_teste)             # Testa o modelo com predição\n",
        "        self.accuracy = metrics.accuracy_score(prediction, self.y_teste)\n",
        "        self.precision = metrics.precision_score(prediction, self.y_teste, average='weighted')\n",
        "        self.recall = metrics.recall_score(prediction, self.y_teste, average='weighted')\n",
        "        self.f1_score = metrics.f1_score(prediction, self.y_teste, average='weighted')\n",
        "        self.confusion_matrix = metrics.confusion_matrix(prediction, self.y_teste)\n",
        "        self.classification_report = classification_report(self.y_teste, prediction)\n",
        "\n",
        "        print('\\n TESTE DO MODELO SVM - SUPORT VECTOR MACHINE\\n')\n",
        "\n",
        "        print('Predição:')\n",
        "        print(prediction)\n",
        "        print('\\n')\n",
        "\n",
        "        print('Matriz de Confusão:')\n",
        "        print(self.confusion_matrix)\n",
        "        print('\\n')\n",
        "        print(f'A acurácia do modelo SVM.SVC é de: {round(100*self.accuracy, 2)}%')\n",
        "        print(f'A precisão do modelo SVM.SVC é de: {round(100*self.precision, 2)}%')\n",
        "        print(f'O Recall   do modelo SVM.SVC é de {round(100*self.recall, 2)}%')\n",
        "        print(f'O F1 Score do modelo SVM.SVC é de {round(100*self.f1_score, 2)}%')\n",
        "        print(f'\\n\\nRelatório de Classificação: \\n {self.classification_report}')\n",
        "\n",
        "    def Treinamento_LinearRegression(self):\n",
        "        \"\"\"\n",
        "        Treina o modelo de machine learning.\n",
        "\n",
        "        Detalhes:\n",
        "            * Utilize a função `train_test_split` para dividir os dados em treinamento e teste.\n",
        "            * Escolha o modelo de machine learning que queira usar. Lembrando que não precisa ser SMV e Regressão linear.\n",
        "            * Experimente técnicas de validação cruzada (cross-validation) para melhorar a acurácia final.\n",
        "\n",
        "        Nota: Esta função deve ser ajustada conforme o modelo escolhido.\n",
        "        \"\"\"\n",
        "        # Dividindo os dados principais em treinamento and teste: 70% (treinamento) e 30% (testes)\n",
        "\n",
        "        iris_data = self.df.copy()\n",
        "\n",
        "        # Selecionando uma Espécie de Flor = Iris-versicolor\n",
        "        data = iris_data[iris_data['Species'] == 'Iris-versicolor'].copy()\n",
        "        data.drop(columns=['Species','SepalLengthCm','SepalWidthCm'],inplace=True)\n",
        "        print('Dados selecionados')\n",
        "        print(f'data: \\n{data.head(20)}')\n",
        "\n",
        "\n",
        "        # Plotando o Dataframe nomeado data tendo o eixo x como 'PetalLengthCm', eixo y como 'PetalWidthCm' e kind='scatter'\n",
        "        data.plot(x='PetalLengthCm', y='PetalWidthCm', kind='scatter')\n",
        "        plt.xlabel('Petal Length')\n",
        "        plt.ylabel('Petal Width')\n",
        "        plt.title('Gráfico Scatter de Petal: Length x Petal Width')\n",
        "        plt.show()\n",
        "\n",
        "        # Agora dividiremos o conjunto de dados em conjuntos de dados de treinamento e teste em (X_treinamento, y_treinamento) e (X_teste,Y_teste)\n",
        "\n",
        "        X=data['PetalLengthCm'].values.reshape(-1,1)\n",
        "        Y=data['PetalWidthCm'].values.reshape(-1,1)\n",
        "\n",
        "        self.X_treinamento, self.X_teste, self.y_treinamento, self.y_teste=train_test_split(X,Y, test_size=0.30,random_state=1)\n",
        "\n",
        "\n",
        "        # Plotting training datasets\n",
        "        plt.scatter(self.X_treinamento, self.y_treinamento)\n",
        "        plt.xlabel('X Treinamento')\n",
        "        plt.ylabel('Y Treinamento')\n",
        "        plt.title('Gráfico Scatter do Dataset de Treinamento')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        # LinearRegression\n",
        "        print('\\nTREINANDO COM O REGRESSÃO LINEAR\\n')\n",
        "\n",
        "        self.model = LinearRegression()\n",
        "        self.model.fit(self.X_treinamento, self.y_treinamento)  # Treina o modelo com os dados de treinamemto\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def Teste_LinearRegression(self):\n",
        "        \"\"\"\n",
        "        Avalia o desempenho do modelo treinado nos dados de teste.\n",
        "\n",
        "        Esta função deve ser implementada para testar o modelo e calcular métricas de avaliação relevantes,\n",
        "        como acurácia, precisão, ou outras métricas apropriadas ao tipo de problema.\n",
        "        \"\"\"\n",
        "        prediction = self.model.predict(self.X_teste)             # Testa o modelo com predição\n",
        "\n",
        "\n",
        "        print('\\n TESTE DO MODELO - REGRESSÃO LINEAR\\n')\n",
        "\n",
        "        # Mostrando o Intercept and Coefficient\n",
        "        print(\"Intercept:\", self.model.intercept_)\n",
        "        print(\"Coefficient:\", self.model.coef_)\n",
        "\n",
        "        print('Predição:')\n",
        "        print(prediction)\n",
        "        print('\\n\\n')\n",
        "\n",
        "        # Plotando Datasets de Teste\n",
        "        plt.scatter(self.X_teste, self.y_teste)\n",
        "        plt.xlabel('X Teste')\n",
        "        plt.ylabel('Y Teste')\n",
        "        plt.title('Gráfico Scatter de Dataset de Teste')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def Train(self):\n",
        "        \"\"\"\n",
        "        Função principal para o fluxo de treinamento do modelo.\n",
        "\n",
        "        Este método encapsula as etapas de carregamento de dados, pré-processamento e treinamento do modelo.\n",
        "        Sua tarefa é garantir que os métodos `CarregarDataset`, `TratamentoDeDados` e `Treinamento` estejam implementados corretamente.\n",
        "\n",
        "        Notas:\n",
        "            * O dataset padrão é \"iris.data\", mas o caminho pode ser ajustado.\n",
        "            * Caso esteja executando fora do Colab e enfrente problemas com o path, use a biblioteca `os` para gerenciar caminhos de arquivos.\n",
        "        \"\"\"\n",
        "        self.CarregarDataset(\"https://github.com/MarcusMacedo1510/curso-python-data-imc/tree/main/iris.data\")  # Carrega o dataset especificado.\n",
        "\n",
        "        # Tratamento de dados opcional, pode ser comentado se não for necessário\n",
        "        self.TratamentoDeDados()\n",
        "\n",
        "        self.Treinamento_SVM()               # Executa o treinamento do modelo SVM\n",
        "        self.Teste_SVM()                     # Executa o teste do modelo SVM\n",
        "        self.Treinamento_LinearRegression()  # Executa o treinamento do modelo LinearRegression\n",
        "        self.Teste_LinearRegression()        # Executa o teste do modelo LinearRegression\n",
        "\n",
        "# Lembre-se de instanciar as classes após definir suas funcionalidades\n",
        "# Recomenda-se criar ao menos dois modelos (e.g., Regressão Linear e SVM) para comparar o desempenho.\n",
        "# A biblioteca já importa LinearRegression e SVC, mas outras escolhas de modelo são permitidas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eUKob_Esj7Bc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Programa principal\n",
        "cl = Iris()\n",
        "cl.Train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "k2gO5A-5asah",
        "outputId": "64afe42b-7da9-4367-8cd1-513113a62a06"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 5 fields in line 42, saw 28\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-000cf8b7defb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Programa principal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-b44de9718d7d>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;34m*\u001b[0m \u001b[0mCaso\u001b[0m \u001b[0mesteja\u001b[0m \u001b[0mexecutando\u001b[0m \u001b[0mfora\u001b[0m \u001b[0mdo\u001b[0m \u001b[0mColab\u001b[0m \u001b[0me\u001b[0m \u001b[0menfrente\u001b[0m \u001b[0mproblemas\u001b[0m \u001b[0mcom\u001b[0m \u001b[0mo\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbiblioteca\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mos\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mpara\u001b[0m \u001b[0mgerenciar\u001b[0m \u001b[0mcaminhos\u001b[0m \u001b[0mde\u001b[0m \u001b[0marquivos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCarregarDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/MarcusMacedo1510/curso-python-data-imc/tree/main/iris.data\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Carrega o dataset especificado.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Tratamento de dados opcional, pode ser comentado se não for necessário\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-b44de9718d7d>\u001b[0m in \u001b[0;36mCarregarDataset\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[1;32m     29\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SepalLengthCm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SepalWidthCm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PetalLengthCm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PetalWidthCm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Species'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mTratamentoDeDados\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 42, saw 28\n"
          ]
        }
      ]
    }
  ]
}